{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Sxn60s9Fd_BOSmhHy9-YqCD6dYkCHJ0l",
      "authorship_tag": "ABX9TyN9GYQdRizY3gPVl1n9NFmx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yashwanth-Chandrakumar/DeepFake-Detection/blob/main/DeepFake_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "model3= keras.models.load_model(\"/content/drive/MyDrive/deep model/deepdetectv4.h5\")"
      ],
      "metadata": {
        "id": "D3h4E8qGhpyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load and preprocess the image\n",
        "img = image.load_img(\"/content/fake_10020.jpg\", target_size=(150, 150))\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0) / 255.\n",
        "\n",
        "# Make predictions\n",
        "predictions = model3.predict(img_array)\n",
        "value = np.argmax(predictions)\n",
        "if value ==1:\n",
        "    print(\"Real\")\n",
        "else:\n",
        "    print(\"Fake\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWTT5402g-7Z",
        "outputId": "59ac738e-f324-4059-9ce0-a7de732118ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "Fake\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepface"
      ],
      "metadata": {
        "id": "DU4zOqPU34cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade requests\n",
        "!pip install --upgrade deepface\n"
      ],
      "metadata": {
        "id": "_-IlMyUJ6Sod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "\n",
        "# Load the pre-trained model\n",
        "model3 = keras.models.load_model('/content/drive/MyDrive/deep model/deepdetectv4.h5')\n",
        "\n",
        "# Open the video file\n",
        "video = cv2.VideoCapture('/content/You Wonâ€™t Believe What Obama Says In This Video! ðŸ˜‰.mp4')\n",
        "\n",
        "# Initialize face detector\n",
        "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "# Initialize an empty list to store predictions\n",
        "predictions = []\n",
        "\n",
        "# Loop over frames\n",
        "while True:\n",
        "    # Read a frame from the video\n",
        "    ret, frame = video.read()\n",
        "\n",
        "    # Break if no more frames\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert frame to grayscale\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Detect faces in the frame\n",
        "    faces = face_detector.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
        "\n",
        "    # Loop over detected faces\n",
        "    for (x, y, w, h) in faces:\n",
        "        # Preprocess the face\n",
        "        face_img = cv2.resize(frame[y:y+h, x:x+w], (150, 150))\n",
        "        face_img = np.expand_dims(face_img, axis=0) / 255.0\n",
        "\n",
        "        # Make a prediction\n",
        "        prediction_probabilities = model3.predict(face_img)\n",
        "        value = np.argmax(prediction_probabilities)\n",
        "        prediction = \"Real\" if value == 1 else \"Fake\"\n",
        "\n",
        "        # Append the prediction to the list\n",
        "        predictions.append(prediction)\n",
        "\n",
        "        # Print face coordinates and prediction\n",
        "        print(f'Face: ({x}, {y}), ({x+w}, {y+h}), Prediction: {prediction}')\n",
        "\n",
        "    # Determine the final result based on majority voting\n",
        "    if predictions:\n",
        "        final_result = max(set(predictions), key=predictions.count)\n",
        "        print(f'Final Result: {final_result}')\n",
        "    else:\n",
        "        print('No faces detected in the video.')\n",
        "\n",
        "# Release the video capture object\n",
        "video.release()"
      ],
      "metadata": {
        "id": "R-fVlRKnh65c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aRbOxCaF4RUh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}